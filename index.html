<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content><meta name="keywords" content><meta name="author" content="Conglei Xu"><meta name="copyright" content="Conglei Xu"><title>Understanding the infinite world within a finite life. | Conglei Xu</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="author-info"><div class="author-info__avatar text-center"><img src="https://raw.githubusercontent.com/yao2jiang/blog_images/master/bolg_index/new.jpg"></div><div class="author-info__name text-center">Conglei Xu</div><div class="author-info__description text-center"></div><div class="follow-button"><a href="https://github.com/xiaojianhai">Follow me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">19</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">10</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">11</span></a></div></div></div><nav id="nav" style="background-image: url(https://raw.githubusercontent.com/yao2jiang/blog_images/master/bolg_index/header.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Conglei Xu</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="site-info"><div id="site-title">Conglei Xu</div><div id="site-sub-title">Understanding the infinite world within a finite life.</div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2023/10/18/LLMs-tuning/">Conclusion for Fine-Tuning on LLMs</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-10-18</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Natural-Language-Processing/">Natural Language Processing</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Large-Language-Models/">Large Language Models</a></span><div class="content"><p>#Overview</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p> Based on the generation of prompt, the fine-tuning techeniques can be categoried into two groups:</p>
<ol>
<li><p>hard-prompt</p>
<ul>
<li>AutoPrompt</li>
</ul>
</li>
<li><p>soft-promt</p>
<ul>
<li>prefix-tuning</li>
<li>p-tuning</li>
<li>lora tuning</li>
</ul>
</li>
</ol>
<h1 id="auto-prompt"><a href="#auto-prompt" class="headerlink" title="auto-prompt"></a>auto-prompt</h1><p>auto-prompt was proposed by Taylor Shin for mask language models. It can generate a prompt template for different tasks.<br>The template contains three part $ x_inp $, $ x_trig $ and $ mask $. auto-prompt only update the embedding of trig words in<br>traing process. Take the sentiment classification task as an example：</p>
<p>“ a real joy. * atmosphere alot dialogue Clone totally * [MASK] “</p>
<p>$$ p(y|x_{prompt}) = \sum_{w \in V_y} p([MASK]=w|x_{prompt}) $$</p>
<p>for binary sentiment analysis the y will be positive and negative. </p>
<h1 id="prefix-tuning"><a href="#prefix-tuning" class="headerlink" title="prefix-tuning"></a>prefix-tuning</h1><p>Considering the poor expressive ability of tokens in vocabulary, prefix-tuning uses two trainable prefix encdoing, which are updated in training process.<br>The prefix heads are inserted into models by layers. </p>
<p>![Fig1. prefix-tuning]</p>
<p>some drawbacks are existed in prefix-tuning: first, the prefix token occupy the length of input sentence; if we have many tasks, prefix-tuning will save a copy of model<br>for each tasks; moreover, it hard to distinghuis the number of tokens for prefix-tuning.</p>
<h1 id="prompt-Tuning"><a href="#prompt-Tuning" class="headerlink" title="prompt-Tuning"></a>prompt-Tuning</h1><p>Unlike the prefix-tuning insert prefix-embedding into each layaer and then train it by backpropogation, prompt-tuning just add some<br>task-specific tokens at the input layer, then these tokens are trained by backpropogation.</p>
<p>In application, the task-specific embeddings are seperated with the Language models. </p>
<p>Both the prompt-tuning and prefix-tuning are occupied the space of input and the number of used tokens are task-specific. </p>
<h1 id="lora"><a href="#lora" class="headerlink" title="lora"></a>lora</h1><p>The key idea of lora is that over-parametrized large models reside on a low intrinstic dimension. It saids the change in weight<br>during models adaption also has a low intrinstic rank/dimension. concretely, if $ W_{nk} $ denotes the weights of models, $ \nabla w $,<br>denoting the change in weghts, is a low intrinstic matrix. </p>
<p>LLMs are trained to capture the general representation of their domains. These models capture a variety of features which allow them to used<br>for diverse tasks. However, when adapting such a model, only a few parameters needs to be updated. This means that the update matrix $\nabla w$ can<br>be a low rank matrix. </p>
<p>lora use the two low rank matrices $ B_{nr} A_{rk} $, which is the matrix decompostion of $ \nabla w_{nk} $,  to represent $ \nabla w_{nk} $.<br>$ r &lt;&lt; k $.So the $ W_{nk} + \nabla w_{nk} $ turned into $ W_{nk}x + BAx $. A random Gaussion initialization is used for A and B is initialized to 0.<br>the $ BA=0 $ at the begining. The update $ BA $ is additonally scaled with a factor $ a/r $</p>
<p>![Fig2. Modified forward pass using lora-ranking decompostion] ()</p>
<ol>
<li>lora doesn’t occupy the input space.</li>
<li>No additional inference time in lora. </li>
<li>Easier swithc between tasks: Swapping only the lora wights as opposed to all the parameters allows cheaper and faster switching between tasks. </li>
</ol>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/09/21/week5/">week5</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-09-21</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/week-summary/">week summary</a></span><div class="content"><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><h1 id="Basic-Knowledge-in-Reinforcement-Learning"><a href="#Basic-Knowledge-in-Reinforcement-Learning" class="headerlink" title="Basic Knowledge in Reinforcement Learning"></a>Basic Knowledge in Reinforcement Learning</h1><h2 id="Basic-Concepts"><a href="#Basic-Concepts" class="headerlink" title="Basic Concepts"></a>Basic Concepts</h2><p>** Environment： **</p>
<ol>
<li>reward function: give a feedback to the agent’s action.</li>
<li>transitional probability: give a new state based on the current state and agent’s action.<br>transition step: for a state $ s $, the agent choose to take an action, ant then the environment gives<br>a new state $ \acute{a} $ and a reward r. this known as a transition step, represented by a tuple $ (s, a, \acute{a}, r) $.</li>
</ol>
<p>we use $ \mathbb{P} $ represent the probability of a transiton step, $ P $ denote the function of a transition from $ s $ to<br>$ \acute{s} $.</p>
<p>$$ P(\acute{s}, r | a, s) = \mathbb{P}[ S_{t+1}={\acute{s}, r | S_t=s, a } ] $$</p>
<p>$$ P(\acute{s}|a, s) = \sum_{r} {\mathbb{P}[S_{t+1}={\acute{s}, r | S_t=s, a}]} $$</p>
<p>The reward function $ R $ could be either determinsitc(the reward is always the same) or stochastic(the reward vary according to some probability<br>distribution).</p>
<p>** Agent: **</p>
<p>agent take actions based on policy and then get future reward for this policy. The goal of RL is to find the optimical policy<br>to maximize the future reward. </p>
<p>policy tells the agent which action to take in state s. It is mapping from state s to action a.<br>It can be either determinsitc or stochastic:</p>
<ul>
<li>determinsitc: $ \pi(s) = a $ </li>
<li>stochastic: $ \pi(s) = \mathbb{P}[A=a|S=s] $</li>
</ul>
<p>the state-value of a state s is the expected return if we are in this state at time t, $ S_t = s $.</p>
<p>$$ V_{\pi}(s) = E[G_t|S_t=s] $$</p>
<p>the action value of a state-action pair:</p>
<p>$$ Q_{\pi}(s,a)=E[ G_t | S_t=s, A_t=a ] $$</p>
<p>$$ V_{\pi}(s) = \sum_{a}{Q_{\pi}(s, a)\pi(a, s)} $$</p>
<h2 id="value-based-methods"><a href="#value-based-methods" class="headerlink" title="value-based methods"></a>value-based methods</h2><p>In value-based methods, the goal is to mininze the loss between predicted value and target value to approximate true<br>action-value function. we could get the policy form optimical action-value function implicitly.</p>
<p>$$ Q_{\pi}^{\ast}=max_{\pi}Q_{\pi} $$ </p>
<p>$$ \pi^{\ast}=\mathop{argmax}\limits_{\pi}Q_{\pi} $$</p>
<p>** Bellman Expections Equations **</p>
<p>$$ V_{\pi}(s) = \sum_{a}Q_{\pi}(s,a)\pi(a|s) $$</p>
<p>$$ Q_{\pi}(s,a) = R(s, a) + \lambda \sum_{\acute{s}} \mathbb{P}<em>{s,\acute{s}}^{a}V</em>{\pi}(\acute{s}) $$ </p>
<p>$$ V_{\pi}(s) = \sum_{a}\pi(a|s)(R(s, a) + \lambda \sum_{\acute{s}}  \mathbb{P}<em>{s,\acute{s}}^{a}V</em>{\pi}(\acute{s}) $$</p>
<p>$$ Q_{\pi}(s,a) = R(s, a) + \lambda \sum_{\acute{s}} \mathbb{P}<em>{s,\acute{s}}^a(\sum</em>{a}Q_{\pi}(\acute{s},a)\pi(a|\acute{s})) $$</p>
<p>** Bellman Optimaility Equations **</p>
<p>$$ V^{\ast} = max_{a} Q^{\ast}(s,a) $$ </p>
<p>$$ Q^{\ast| = R(s,a) + \lambda \sum_{\acute{s}} \mathbb{P}_{s,\acute{s}}^{a}V^{\ast}(\acute{s}) $$</p>
<p>$$ V^{\ast} = max_{a} (R(s, a) + \lambda \sum_{\acute{s}} \mathbb{P}_{s,\acute{s}}^{a}V^{\ast}(\acute{s})) $$</p>
<p>$$ Q^{\ast}(s,a) = R(s,a) + \lambda \mathbb{P}<em>{s,\acute{s}}^amax</em>{a}Q_(\acute{s},a)\pi(a|\acute{s}) $$</p>
<p>** Dynamic Progamming **</p>
<p>In problems can be solved by dynamic progamming. the DP process can be seen as a RL process to achieve optimical Bellman Equations.</p>
<p>There ar two primary DP methods: Policy Iteration, Value Iteration.</p>
<p>** Policy Iteration **</p>
<p>** Intialization **</p>
<p>Start with an arbitiary policy ${pi}$ and arbitiary value function $ V $.</p>
<p>** Policy Evaluation **</p>
<p>Given a policy $ {pi} $, compute its value function $ V^{\pi} $. This involves solving the Bellman Expections Equations<br>for the current policy until convergence.</p>
<p>$$ V_{\pi}(s) = \sum_{a}\pi(a|s)(R(s, a) + \lambda \sum_{\acute{s}}  \mathbb{P}<em>{s,\acute{s}}^{a}V</em>{\pi}(\acute{s}) ) $$</p>
<p>** Policy Improvement **</p>
<p>Now, we have the value function $ V^{\pi} $ for the current policy, we can attempt improve the policy. For each state $ s $, select the<br>action a that maxmize the expected value.</p>
<p>$$ \acute{\pi} = argmax_{a} (R(s, a) + \lambda \sum_{\acute{s}}  \mathbb{P}<em>{s,\acute{s}}^{a}V</em>{\pi}(\acute{s}) ) $$</p>
<p>The new policy is guranteed to be at least as good as the old policy $ \pi $. we can stop the Iteration if they are same.</p>
<p>** Iteration **</p>
<p>Repeat steps 2 and stpes 3 until the policy remains unchanged between two concective Improvements.</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/09/04/week4/">week4</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-09-04</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/week-summary/">week summary</a></span><div class="content"><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>This week make a conclusion of usage of random backage in Pytorch and Numpy, Cosice similarity and multiprocessing combined with early<br>stoping in Pytorch.</p>
<h1 id="random-package"><a href="#random-package" class="headerlink" title="random package"></a>random package</h1><h2 id="Tensors-and-Ndarray"><a href="#Tensors-and-Ndarray" class="headerlink" title="Tensors and Ndarray"></a>Tensors and Ndarray</h2><p>The random package can generate Tensors(ndarray) under different distribution, including uniform distribution, stand normal distribution and<br>custom distribution.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">stand normal distribution</span><br><span class="line">torch.randn() </span><br><span class="line">np.random.randn() return either a narray or a float</span><br><span class="line"></span><br><span class="line">uniform distribution random samples from a uniform distribution over [0, 1)</span><br><span class="line">torch.rand()</span><br><span class="line">np.random.rand(shape1, shape0)</span><br><span class="line"></span><br><span class="line">random int numbers over [low, high] with shape s=(9, 9)</span><br><span class="line">torch.randint(low, high, s)</span><br><span class="line">np.random.randint(low, high, s)</span><br><span class="line"></span><br><span class="line">custom operation</span><br><span class="line">np.random.permuation(10) # same as np.random.shuffle(np.arange(10))</span><br><span class="line">t = torch.tensor([[1, 2], [3, 4]])</span><br><span class="line">row = torch.randperm(2)</span><br><span class="line">col = torch.randperm(2)</span><br><span class="line">t = t[row[:, None], col] # row[:, None] add a new dimension for row tensor</span><br><span class="line"></span><br><span class="line">with view</span><br><span class="line">idx = torch.randperm(t.nelement())</span><br><span class="line">t = t.view(-1)[idx].view(t.size)</span><br></pre></td></tr></table></figure>

<h2 id="Methods-for-Tensors-Initialization"><a href="#Methods-for-Tensors-Initialization" class="headerlink" title="Methods for Tensors Initialization"></a>Methods for Tensors Initialization</h2><p>two types of initialization for tensors:<br>by the data.fill_ mehtod of tensor object or by nn.init.method</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">manual initialization</span><br><span class="line">linear_layer = nn.Linear(5, 4)</span><br><span class="line">linear_layer.weight.data.fill_(0.0)</span><br><span class="line">linear_layer.bias.data.fill_(0.0)</span><br><span class="line"></span><br><span class="line">Initialized by nn.init</span><br><span class="line">nn.init.zeros_(weight)  # all initialized methods need a tensor object as the input</span><br><span class="line">nn.init.ones_(weight)</span><br><span class="line">nn.init.uniform(linear_layer.weight, a=0.0, b=1.0)</span><br><span class="line">nn.init.normal_(linear_layer.weight, mean=0.0, std=1.0)</span><br><span class="line"></span><br><span class="line">nn.init.xavier_uniform_(weight)</span><br><span class="line">nn.init.xavier_normal_(weight)</span><br><span class="line"></span><br><span class="line">nn.init.kaiming_uniform(weight, nonlinearity=&apos;relu&apos;)</span><br><span class="line">nn.init.kaiming_normal_(weight, nonlinearity=&apos;relu&apos;)</span><br><span class="line">nn.init.orthogonal_(weight)</span><br><span class="line"></span><br><span class="line">custom initialization</span><br><span class="line">def defiend_initialization(input_tensor):</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">	    tensor.fill_(1.0)</span><br></pre></td></tr></table></figure>

<h1 id="Indexing-of-Tensors-in-Pytorch"><a href="#Indexing-of-Tensors-in-Pytorch" class="headerlink" title="Indexing of Tensors in Pytorch"></a>Indexing of Tensors in Pytorch</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">Integer array indexing</span><br><span class="line">two indicies should have same length and the Indexing is elementwise</span><br><span class="line">row = torch.tensor([1, 2]) #one dimension</span><br><span class="line">columns = torch.tensor([1, 2])</span><br><span class="line"></span><br><span class="line">boolean array Indexing</span><br><span class="line">y = [x&gt;1]</span><br><span class="line"></span><br><span class="line">Mixing integer and slice Indexing</span><br><span class="line">y = x[i, :5]</span><br><span class="line"></span><br><span class="line">None indexing for new slice indexing </span><br><span class="line">y = x[..., None]</span><br><span class="line"></span><br><span class="line">tensor indexing </span><br><span class="line">indicies = torch.tensor([[1, 3], [2, 4]]) # (2 * 2)</span><br><span class="line">t = torch.randn(5, 5)</span><br><span class="line">y = t[indicies]  (2*2*5)</span><br><span class="line"></span><br><span class="line">two tensor indexing by broadcasting </span><br><span class="line">row = torch.tensor([1, 2])</span><br><span class="line">column = torch.tensor([0, 1])</span><br><span class="line">y = t[row[:, None], column]</span><br><span class="line"></span><br><span class="line">row(2) -&gt; row(2, 1), then Indexing broadcasting to row(2, 2) [[1, 1], [2, 2]]</span><br><span class="line">column(2) -&gt; column(2, 2) [[0, 1], [0, 1]]</span><br><span class="line">the result has the shape (len(row), len(column)) each result[i][j] will be t[row[i], [column[j]]</span><br></pre></td></tr></table></figure>

<h1 id="Hadnling-Negative-Value-in-Cosine-Similarity"><a href="#Hadnling-Negative-Value-in-Cosine-Similarity" class="headerlink" title="Hadnling Negative Value in Cosine Similarity"></a>Hadnling Negative Value in Cosine Similarity</h1><p>consine similarity in torch.nn.cosine_similarity() can handle three dimension data</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Rescale_simiarity</span><br><span class="line">Rescale_simiarity = (cosine_similarity + 1) / 2</span><br><span class="line"></span><br><span class="line">Change it to consine distance</span><br><span class="line">cosine_distance = 1 - consine_similarity</span><br></pre></td></tr></table></figure>

<h1 id="Pytorch-Multiprocessing-Combined-with-Early-Stoping"><a href="#Pytorch-Multiprocessing-Combined-with-Early-Stoping" class="headerlink" title="Pytorch Multiprocessing Combined with Early Stoping"></a>Pytorch Multiprocessing Combined with Early Stoping</h1><p>When training neural networks on multi-gpus, it’s essential to use shared variables and a “Lock” to implement early stoping.<br>The primary is to ensure that ass the different processes cease operations at the same point.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Value, Lock  Value are ctype objects, whcih can shared </span><br><span class="line"></span><br><span class="line">def train(*args):</span><br><span class="line">    for epoch in range(1, num_epoch + 1):</span><br><span class="line">	    ...</span><br><span class="line">		with best_f1_lock:</span><br><span class="line">		    if best_f1.value &lt; eval_f1:</span><br><span class="line">			    best_f1.value = eval_f1</span><br><span class="line">				patience_counter = 0</span><br><span class="line">			else:</span><br><span class="line">			    patience_counter += 1</span><br><span class="line">				if patience_counter &gt;= patience:</span><br><span class="line">				    stop.flag.value = 1</span><br><span class="line">		if stop_flag.value == 1:</span><br><span class="line">		    break</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    best_f1 = Value(&apos;d&apos;, -1.0) double float</span><br><span class="line">	best_f1_lock = Lock()</span><br><span class="line">	stop_flag = Value(&apos;i&apos;, 1) flag to signal processes to stop</span><br></pre></td></tr></table></figure>

<h1 id="Trivial-Knowledge"><a href="#Trivial-Knowledge" class="headerlink" title="Trivial Knowledge"></a>Trivial Knowledge</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">torch.sort() return sorted_tensor, and indicies</span><br><span class="line"></span><br><span class="line">for torch.where() the condiion tensor and two tensors &apos;x&apos; and &apos;y&apos; should be broadcastable to the same shape</span><br><span class="line"></span><br><span class="line">torch.where(condition, x, y)</span><br><span class="line"></span><br><span class="line">torch.unsqueeze(x, 0)  add dimension same as x[None, :]</span><br><span class="line">torch.squeeze(x, 0)</span><br><span class="line"></span><br><span class="line">x = torch.ones(5,1)</span><br><span class="line">y = x.repreat(1, 5) (5, 5)</span><br></pre></td></tr></table></figure>

</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/08/28/week3/">week3</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-08-28</time><div class="content"><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>The knowledge acquired this week can be categorized into three sections:</p>
<ol>
<li>Pytorch’s Autograd mechanism.</li>
<li>Techniques for effective training.</li>
<li>Miscellaneous information.</li>
</ol>
<h1 id="Pytorch’s-Autograd-mechanism"><a href="#Pytorch’s-Autograd-mechanism" class="headerlink" title="Pytorch’s Autograd mechanism"></a>Pytorch’s Autograd mechanism</h1><h2 id="Computational-Graph"><a href="#Computational-Graph" class="headerlink" title="Computational Graph"></a>Computational Graph</h2><p>In Pytorch, a Computational graph is constructed when we mathmatical operations are performed on tensors.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor(2.0, requires_grad=True)</span><br><span class="line">b = torch.tensor(3.0, requires_grad=True)</span><br><span class="line">c = a * b</span><br></pre></td></tr></table></figure>

<p>The computational graph for code above is structed as follows:<br><img src="https://raw.githubusercontent.com/yao2jiang/blog_images/master/pictures/week3/computational_graph.png" alt="Fig1. process of bulding computational graph"><br>there are two types of nodes in a Computational Graph: leaf nodes and root nodes.</p>
<ul>
<li>leaf nodes are the input tensors that store the gradient by default in their <strong>grad</strong> attributes.</li>
<li>root nodes are the output(intermediate) tensors output. by default, they don’t have a <strong>grad</strong> attribute but process a <strong>grad_fn</strong> object instead.</li>
</ul>
<h2 id="Grad-Modes"><a href="#Grad-Modes" class="headerlink" title="Grad Modes"></a>Grad Modes</h2><p>In Pytorch, there are three gradient modes in Pytorch: Grad mode, no-grad mode and inference mode(introduced in version 1.9).</p>
<ul>
<li>grad mode: This is the default mode in Pytorch. the attribute <strong>requires_grad</strong> in functional only in this mode.</li>
<li>no-grad mode: Computations are never recorded in this mode. <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with torch.no_grad():</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>The above code act as a context manager to activate no-grad mode. This mode provides a convient method to prevent gradient recording without necessity of<br>setting <strong>requires_grad</strong> as false.</p>
<ul>
<li>inference mode: It is a feature introduced in Pytorch 1.9 . It is similar to the no-grad mode but offers high effciency.<br>tensors initialized in this mode shouldn’t be used outside its context.</li>
</ul>
<h2 id="Hook"><a href="#Hook" class="headerlink" title="Hook"></a>Hook</h2><p>A hook is basically a function that is executed when we either forward or backward is called.<br>There are two primary types of hook: tensor hooks and module hooks.</p>
<ul>
<li>module hooks: Utilized through the method <code>moduel.register_forward_hook()</code></li>
<li>tensor hooks: For root nodes, the hook is embedded within the <strong>grad_fn</strong> attribute.<br>Below is an example showcasing the useage of hooks:<br><img src="https://raw.githubusercontent.com/yao2jiang/blog_images/master/pictures/week3/hook.png" alt="useage of hood"><br>Root nodes can retain gradients using <code>retain_grad()</code> function.</li>
</ul>
<h1 id="Techniques-for-effective-training"><a href="#Techniques-for-effective-training" class="headerlink" title="Techniques for effective training"></a>Techniques for effective training</h1><h2 id="1-Gradient-Accumulation"><a href="#1-Gradient-Accumulation" class="headerlink" title="1. Gradient Accumulation"></a>1. Gradient Accumulation</h2><p>This method can make traning with a big batch size even with limited computational resource.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">loss.backward()</span><br><span class="line">if condition:</span><br><span class="line">    optimizer.step()</span><br><span class="line">	optimizer.zero_grad()</span><br></pre></td></tr></table></figure>

<h2 id="2-Batch-Normalization"><a href="#2-Batch-Normalization" class="headerlink" title="2. Batch Normalization"></a>2. Batch Normalization</h2><ul>
<li>Compute statistics<br>$$ \mu_B = \frac{1}{m}\sum_{i=1}^{m}x_i  $$<br>$$ \sigma_B^2 = \frac{1}{m}(x_i - \mu_B)^2 $$</li>
<li>Normalize<br>$$ \hat{x_i}^2 = \frac{x_i - \mu}{\sqrt{\sigma_B^2 + \epsilon}} $$<br>$\epsilon$ is a samll constant added for numerical stability.</li>
<li>Scale and shift<br>$$ y_i = \gamma x_i + \beta $$<br>$\gamma$ and $\beta$ are two learnable parameters.<br>scale and shift operations are curcial there are cases where the network might perfer the activations to have a differtn mean and variance<br>rather than 0 and 1.<br>During inference, there are not enough batches to compute the mean and variance. Instead, the runing average of the mean and variance, computed<br>during training, is used. </li>
<li>Advantages<br>Faster Convergence:<br>Ensuring the activations have a consistent distribution;<br>Mitigate the risk of activations reaching extremly high or low values. </li>
</ul>
<h2 id="3-Layer-Normalization"><a href="#3-Layer-Normalization" class="headerlink" title="3. Layer Normalization"></a>3. Layer Normalization</h2><p>while Batch Normalization normalizes across the batch dimension, Layer Normalization normalizes across the featuer dimension.<br>It is useful for sepcific architecture like the RNN series.</p>
<h1 id="Miscellaneous-information"><a href="#Miscellaneous-information" class="headerlink" title="Miscellaneous information"></a>Miscellaneous information</h1><p>In Pytorch, the broadcasting should follow the rules:</p>
<ol>
<li>Each tensors has at least one dimension. </li>
<li>The dimension sizes must be equal, one of them is 1, or one of them doesn’t exists.</li>
</ol>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/08/09/week2/">Week 2</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-08-09</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/week-summary/">week summary</a></span><div class="content"><h1 id="Basic-Knowledge-of-Reinforcement-Learning"><a href="#Basic-Knowledge-of-Reinforcement-Learning" class="headerlink" title="Basic Knowledge of Reinforcement Learning"></a>Basic Knowledge of Reinforcement Learning</h1><p>Two core components:</p>
<ol>
<li>Environment:<br>In RL, the environment provides a reward for agent’s action based on a concrete state. The current state is then altered according to the choose action and the corresponding transition probability P.</li>
<li>Agent:<br>The agent select actions for the current state based on a policy to maximize the future reward.<h2 id="detailed-concepts-of-RL"><a href="#detailed-concepts-of-RL" class="headerlink" title="detailed concepts of RL"></a>detailed concepts of RL</h2>Action: The set of all possible moves or decisions that an agent can make.<br>State: The current situation of the environment.<br>Policy: A strategy used by the agent to decide which action to take in a given state.<br>Value Function: Represented the expected cumulative future reward that an agent can obtain from a particular state or state-action pair.<br>Fully known Environment: The agent knows the reward of each action and the state transition probabilities precisely. All the dynamic problems<br>can be addressed using RL, Where the agent know the environment.</li>
</ol>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/07/30/week1/">Week 1</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-07-30</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/week-summary/">week summary</a></span><div class="content"><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>the tasks accomplished this week can be categoried into two areas, one is about Natural Language Processing and the other is research in fairness.<br>for NLP:</p>
<ol>
<li>comprehended the details of modifing models strucuture for efficient fine-tuning algorithms in ‘pefg’.</li>
<li>understand the basic methods in data augumentation including word subsitute-based methods and pre-trained models-based methods.<br>As for individual fairness:</li>
<li>finished the data loading process for subgraph view of the individual fairness method.</li>
</ol>
<h1 id="Implementation-of-lora-in-‘peft’"><a href="#Implementation-of-lora-in-‘peft’" class="headerlink" title="Implementation of lora in ‘peft’"></a>Implementation of lora in ‘peft’</h1><p>The initialization process of Lora has two steps:</p>
<ol>
<li><p>Generation of the whole ‘PeftConfig’ based on the given arguments and based pre-trained configuration.<br>The main function is ‘self.base_model.add_appater’ from self.add_appater in the PeftModel Class.<br>Taking Lora as example, ‘self.base_model.add_appater’ refers to the ‘add_appater’ function of the ‘LoraModel’.<br>Within this function, ‘slef._prepare_lora_config’ function will genearte the completed lora configuration(setting the ‘module_to_save’ argument via a pre-defined mapping).</p>
</li>
<li><p>Insertion of the adapter layers into the base models.<br>the main function of this is ‘self._find_and_place’ function in ‘LoraModel’.<br>This identifies the parent modules of the target modules(‘module_to_save’), then create new modules and replace the old target modules with these.</p>
</li>
</ol>
<p>the entire process follows this order:<br>‘get_peft_model()’-&gt; ‘PeftModel.init()’ -&gt; ‘self.add_appater()’ -&gt; ‘self.base_model.add_appater()’</p>
<h1 id="Data-augumentation"><a href="#Data-augumentation" class="headerlink" title="Data augumentation"></a>Data augumentation</h1><ol>
<li>Subtitue-based methods</li>
</ol>
<p>The main idea of this method lies in substituting certain words in sentence with others that are either defined in dictionary, like wordnet, or genearted by language models.</p>
<ol start="2">
<li>Auto-regressive models</li>
</ol>
<p>this method is to genearte new sentences by prompt.</p>
<h1 id="Usage-of-packages"><a href="#Usage-of-packages" class="headerlink" title="Usage of packages"></a>Usage of packages</h1><ol>
<li>Difference between ‘named_children()’ and ‘named_modules()’ in PyTorch.<br>‘named_children’ return the name and module for each immedicate child module of models.<br>‘named_modules’ return the name and module of a model including nested sub-modules.</li>
</ol>
<p>2.LanguageModel Head<br>LM heas is the final layer of auto-regressive models that transforms the model’s internal representation into predictions about the<br>next word in sentence.</p>
<p>In other models, LM-head will refer to some classification heads.</p>
<ol start="3">
<li>Others<br>using ‘setattr(parent, target_name, value)’ to modify structure of models.<br>‘labelBinarizer()’ converts multi-class labels to binary labels.<br>‘np.nonzero()’ return a tuple of array. one for each dimension.</li>
</ol>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2022/01/27/Titanic/">Titanic</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2022-01-27</time><div class="content"></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/06/21/2019-review/">2019_review</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-21</time><div class="content"></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/09/24/basic-statistics-knowledge/">机器学习常犯的统计错误</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-09-24</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/statistics/">statistics</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/theory/">theory</a></span><div class="content"><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
<p><a href="https://www.quora.com/What-are-some-common-errors-in-machine-learning-caused-by-poor-knowledge-of-statistics" target="_blank" rel="noopener">原文链接</a><br>  当我们进行机器学习、深度学习的实验的时候，常常只注重于算法的设计，而忽略了统计学的相关知识，比如不注意<br> <strong>dimensionality constant</strong> 和数据的<strong>probability distribution</strong>从而导致许多问题，下面的内容，我会来介绍这<br> 两项内容。</p>
<h1 id="Dimensionality-constant-维度常量-and-the-Curse-of-Dimensionality-维度噩梦）"><a href="#Dimensionality-constant-维度常量-and-the-Curse-of-Dimensionality-维度噩梦）" class="headerlink" title="Dimensionality constant(维度常量) and the Curse of Dimensionality(维度噩梦）"></a>Dimensionality constant(维度常量) and the Curse of Dimensionality(维度噩梦）</h1><p>  维度常量是用来衡量统计模型对应样本的数量是否足够，下面我们用一个例子来详细阐述维度常量，假设现在样本的特征空间是100维，<br>样本的个数是500维，样本的矩阵大小是100*500，维度常量=维度/样本矩阵的大小=100/500=1/5，它代表在100维的特征空间中，<br>每一个基础的特征都包含500个样本的数据，维度常量的值将会很大程度上影响模型的效果，我们通常使得维度常量的值尽量接<br>近0（特征空间和样本数目都很大，但是样本数目更大）如果维度常量的值过大，则表明相对于特征空间的维度来说样本的数目<br>太少也就是每个特征的样本数量太少，这种情况我们采用PCA，linerar regression,将会得到不准确的结果。</p>
<p>  在学习过程中，样本的个数将会随之特征空间的增大，呈现指数增长<strong>Curse of Dimensionality</strong>如下图所示：<br><img src="https://raw.githubusercontent.com/xiaojianhai/blog_images/master/pictures/statistics/1.png" alt="avatar"></p>
<p>  在平常的模型中，通常会将维度常量设置成非常接近0的数，但是现实世界中也存在一些特列，比如当我们需要训练金融领域的模型<br>时，如果我们将维度常量设置成很大，模型将会学习到一些错误的相关性和信息，因为金融数据更多的是依赖于现在的数据对于过去的<br>数据依赖很少，这时我们需要一个大的维度常量，减小一些时间较长的样本数据的影响。</p>
<h1 id="Normality-of-data-数据的正态性）"><a href="#Normality-of-data-数据的正态性）" class="headerlink" title="Normality of data(数据的正态性）"></a>Normality of data(数据的正态性）</h1><p>  我们大多数的算法模型，例如线性回归，深度学习模型，都需要输入数据的符合正态分布，所以在进行模型训练的时候，我们首先需要<br>知道模型的数据分布，实际生活中，由于缺乏统计学的知识，我们会将所有数据分布类似锥形的分布都当作是正态分布。<br><img src="https://raw.githubusercontent.com/xiaojianhai/blog_images/master/pictures/statistics/2.jpg" alt="avatar"><br>第一张图片显示了从供水系统管道中水下测量的噪声样本，当我们第一眼看到这数据的时候，很容易的就认为这是正态分布，再来看第二张图<br>，它是噪声样本和具有相同均值，方差的正态分布；图三是将下x,y从线性映射成log 级别后的图片，我们可以很清楚的看出噪声样本于正态<br>分布的形状差很多，这其实是一个‘heavy-tailed data distribution’,当我们在判断数据分布的时候，不仅要从均值方差去判断，有时候还需要<br>对数据分布进行恒等变化来确定数据的分布。</p>
<h1 id="Ignoring-sampling-error"><a href="#Ignoring-sampling-error" class="headerlink" title="Ignoring sampling error"></a><a href="http://www.cs.cmu.edu/~tom/10601_sp08/slides/evaluation-2-13.pdf" target="_blank" rel="noopener">Ignoring sampling error</a></h1><h1 id="Choosing-the-wrong-Loss-functions"><a href="#Choosing-the-wrong-Loss-functions" class="headerlink" title="Choosing the wrong Loss functions"></a><a href="https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0" target="_blank" rel="noopener">Choosing the wrong Loss functions</a></h1><h1 id="Correlation-vs-Causation"><a href="#Correlation-vs-Causation" class="headerlink" title="Correlation vs Causation"></a><a href="https://towardsdatascience.com/correlation-is-not-causation-ae05d03c1f53" target="_blank" rel="noopener">Correlation vs Causation</a></h1></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/09/20/bert/">bert</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-09-20</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/paper/">paper</a></span><div class="content"><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
<p>  这篇博客，我会深入的分析，BERT模型之所以带来效果提升的原因。</p>
<p>  在下面的介绍开始以前，我先把一些相关的论文以及结构放在下面，下面的博客内容将会引用下面的论文中的内容。</p>
<ol>
<li><p>“Transformer” 特征提取器，这是BERT的基础结构，也是BERT效果提升的根本原因，介绍Transformer的论文:<a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener">Attention is all you need</a></p>
</li>
<li><p>”OpenAI GPT” 第一次用 “Transformer” 特征提取器在大规模的预训练数据上建立语言模型，然后应用到下游的任务，介绍GPT的论文：<a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">OpenAI’s work</a>。</p>
</li>
<li><p>”BERT“ 在”OpenAI GPT” 基础上进行了几处改动，介绍BERT的论文：<a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noopener">Google‘s work</a>.</p>
</li>
</ol>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>什么是BERT?</p>
<p>  <strong>BERT</strong>（Bidirectional Encoder Representation from Transformer),它是由一些列<strong>Transformer</strong>堆叠在一起构成（只包含Transformer的Decoder),其中双向一词<br>是<strong>BERT</strong>与<strong>GPT</strong>的主要区别，因为<strong>BERT</strong>的<strong>self-attention</strong>在两个方向同时进行而不像<strong>GPT</strong>的主要区别，因为<strong>BERT</strong>的主要区别，因为<strong>BERT</strong>的<strong>self-attention</strong><br>在两个方向同时进行而不像<strong>GPT</strong>的主要区别，因为<strong>BERT</strong>的<strong>self-attention</strong>在两个方向同时进行而不像<strong>GTP**</strong>self-attention<strong>在两个方向同时进行而不像</strong>GTP**<br>具体的来说，对于input sentence:” i love to work nlp”，在<strong>GPT</strong>中 “love” 这个单词只与它的前一个单词”i“ 和它自己本身之间存在<strong>self-attention</strong>的关系，<br>而在<strong>BERT</strong>中单词”i“ 将与句子中的所有单词进行self-attention操作。下面将会进一步介绍GPT不能双向的原因。</p>
<h1 id="结构和双向性"><a href="#结构和双向性" class="headerlink" title="结构和双向性"></a>结构和双向性</h1><p>  <strong>OpenAI GPT</strong> 在建立语言模型的任务基础上来学习参数建立预训练模型，不断提高网络在已知句子的前半部分的前提下预测下一个单词，如果我们在这里利用双向结构<br>建立语言模型，因为self-attention 机制的原因，在预测下一个单词前，这个单词已经和当前单词进行了self-attention操作，已经具有下一个单词的信息<br>从而预测的准确率会很快提高到100%，我们还是拿上面的”i love to  work nlp” 为例子，假如当前单词是“love” 我们首先利用一个双向的self-attention操作。下面将会进一步介绍GPT不能双向的原因。<br>将”i“，”love”,”to”,”work”,”nlp”，这个5个单词的信息嵌入到已知句子中，我们用求得的已知句子去预测下一个单词，因为“to”已经嵌入到上文中，信息已经泄露<br>准确率会很快到100%。</p>
<p>BERT 双向性的实现。</p>
<p>  通过上面对<strong>OpenAI</strong>的分析，我们可以得出一个结论；对于Transformer特征提取器加上双向来建立语言模型不可行，BERT在这里用了一个非常巧妙的手法，为模型加入双向性，<br>它改变了建立语言模型的方式，采取对句子进行随机MASK的”masked language model” 任务和预测下一句子类型的 “next sentence prediction” 的任务两个任务  </p>
<h2 id="Task1-Masked-language-model"><a href="#Task1-Masked-language-model" class="headerlink" title="Task1 Masked language model"></a>Task1 Masked language model</h2><p>BERT 会对输入的所有单词中的15%进行MASK操作，但是MASK操作并不相同，以”My Dog is hariy” 为例子。</p>
<blockquote>
<p>80% 将会被[mask]代替</p>
</blockquote>
<p>example： “My Dog is [mask]”</p>
<blockquote>
<p>10% 将会被随机单词代替</p>
</blockquote>
<p>example： “My Dog is rand”</p>
<blockquote>
<p>10% 将会保持不变</p>
</blockquote>
<p>example:  “My Dog is hariy”</p>
<p>为什么不只用[mask]字符这一种方式替代单词？</p>
<p>  因为如果在fine-tuning过程中，如果被[mask] 的单词没有出现，模型将不会知道在[mask]处存在单词的内容，将认为此处不需要任何输出，将会对模型的效果带来影响。<br>同时我们保留一部分不变的同时，能够让模型学习到mask单词的真正表示。random [mask] 的作用，用来比较模型[mask]的表现能力，使它表现能力比random的表现能力<br>优越。</p>
<p>几点缺点：</p>
<ol>
<li>因为每次都只选取15%的单词进行预测，而语言模型对所有的单词都进行预测，这样会要得到语言模型的loss需要更多次的迭代</li>
</ol>
<h2 id="Task2-Next-Sentence-Prediction"><a href="#Task2-Next-Sentence-Prediction" class="headerlink" title="Task2 Next Sentence Prediction"></a>Task2 Next Sentence Prediction</h2><p>该任务主要内容是，将两个句子输入到模型，然后去预测第二个句子与第一个句子是否同属与一个文本。</p>
<p>为什么需要第二个句子预测任务？</p>
<p> 对于一些句子生成类任务来说，想自动问答，自然语言推理等任务，句子之间的关系对模型有很大的的作用。选取50%的实际的相邻句子，<br> 50% 的随机抽取句子进行训练。</p>
</div><hr></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://raw.githubusercontent.com/yao2jiang/blog_images/master/bolg_index/header.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2023 By Conglei Xu</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://xiaojianhai.github.io/">blog</a>!</div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body></html>