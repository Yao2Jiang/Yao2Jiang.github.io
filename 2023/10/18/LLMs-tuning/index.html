<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Conclusion for Fine-Tuning on LLMs"><meta name="keywords" content="Large Language Models"><meta name="author" content="Conglei Xu"><meta name="copyright" content="Conglei Xu"><title>Conclusion for Fine-Tuning on LLMs | Conglei Xu</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#auto-prompt"><span class="toc-number">1.</span> <span class="toc-text">auto-prompt</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#prefix-tuning"><span class="toc-number">2.</span> <span class="toc-text">prefix-tuning</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#prompt-Tuning"><span class="toc-number">3.</span> <span class="toc-text">prompt-Tuning</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lora"><span class="toc-number">4.</span> <span class="toc-text">lora</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://raw.githubusercontent.com/yao2jiang/blog_images/master/bolg_index/new.jpg"></div><div class="author-info__name text-center">Conglei Xu</div><div class="author-info__description text-center"></div><div class="follow-button"><a href="https://github.com/xiaojianhai">Follow me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">19</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">10</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">11</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://raw.githubusercontent.com/yao2jiang/blog_images/master/bolg_index/header.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Conglei Xu</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">Conclusion for Fine-Tuning on LLMs</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-10-18</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Natural-Language-Processing/">Natural Language Processing</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>#Overview</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p> Based on the generation of prompt, the fine-tuning techeniques can be categoried into two groups:</p>
<ol>
<li><p>hard-prompt</p>
<ul>
<li>AutoPrompt</li>
</ul>
</li>
<li><p>soft-promt</p>
<ul>
<li>prefix-tuning</li>
<li>p-tuning</li>
<li>lora tuning</li>
</ul>
</li>
</ol>
<h1 id="auto-prompt"><a href="#auto-prompt" class="headerlink" title="auto-prompt"></a>auto-prompt</h1><p>auto-prompt was proposed by Taylor Shin for mask language models. It can generate a prompt template for different tasks.<br>The template contains three part $ x_inp $, $ x_trig $ and $ mask $. auto-prompt only update the embedding of trig words in<br>traing process. Take the sentiment classification task as an example：</p>
<p>“ a real joy. * atmosphere alot dialogue Clone totally * [MASK] “</p>
<p>$$ p(y|x_{prompt}) = \sum_{w \in V_y} p([MASK]=w|x_{prompt}) $$</p>
<p>for binary sentiment analysis the y will be positive and negative. </p>
<h1 id="prefix-tuning"><a href="#prefix-tuning" class="headerlink" title="prefix-tuning"></a>prefix-tuning</h1><p>Considering the poor expressive ability of tokens in vocabulary, prefix-tuning uses two trainable prefix encdoing, which are updated in training process.<br>The prefix heads are inserted into models by layers. </p>
<p>![Fig1. prefix-tuning]</p>
<p>some drawbacks are existed in prefix-tuning: first, the prefix token occupy the length of input sentence; if we have many tasks, prefix-tuning will save a copy of model<br>for each tasks; moreover, it hard to distinghuis the number of tokens for prefix-tuning.</p>
<h1 id="prompt-Tuning"><a href="#prompt-Tuning" class="headerlink" title="prompt-Tuning"></a>prompt-Tuning</h1><p>Unlike the prefix-tuning insert prefix-embedding into each layaer and then train it by backpropogation, prompt-tuning just add some<br>task-specific tokens at the input layer, then these tokens are trained by backpropogation.</p>
<p>In application, the task-specific embeddings are seperated with the Language models. </p>
<p>Both the prompt-tuning and prefix-tuning are occupied the space of input and the number of used tokens are task-specific. </p>
<h1 id="lora"><a href="#lora" class="headerlink" title="lora"></a>lora</h1><p>The key idea of lora is that over-parametrized large models reside on a low intrinstic dimension. It saids the change in weight<br>during models adaption also has a low intrinstic rank/dimension. concretely, if $ W_{nk} $ denotes the weights of models, $ \nabla w $,<br>denoting the change in weghts, is a low intrinstic matrix. </p>
<p>LLMs are trained to capture the general representation of their domains. These models capture a variety of features which allow them to used<br>for diverse tasks. However, when adapting such a model, only a few parameters needs to be updated. This means that the update matrix $\nabla w$ can<br>be a low rank matrix. </p>
<p>lora use the two low rank matrices $ B_{nr} A_{rk} $, which is the matrix decompostion of $ \nabla w_{nk} $,  to represent $ \nabla w_{nk} $.<br>$ r &lt;&lt; k $.So the $ W_{nk} + \nabla w_{nk} $ turned into $ W_{nk}x + BAx $. A random Gaussion initialization is used for A and B is initialized to 0.<br>the $ BA=0 $ at the begining. The update $ BA $ is additonally scaled with a factor $ a/r $</p>
<p>![Fig2. Modified forward pass using lora-ranking decompostion] ()</p>
<ol>
<li>lora doesn’t occupy the input space.</li>
<li>No additional inference time in lora. </li>
<li>Easier swithc between tasks: Swapping only the lora wights as opposed to all the parameters allows cheaper and faster switching between tasks. </li>
</ol>
</div></article><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Large-Language-Models/">Large Language Models</a></div><nav id="pagination"><div class="next-post pull-right"><a href="/2023/09/21/week5/"><span>week5</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://raw.githubusercontent.com/yao2jiang/blog_images/master/bolg_index/header.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2023 By Conglei Xu</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://xiaojianhai.github.io/">blog</a>!</div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body></html>