<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="week4"><meta name="keywords" content><meta name="author" content="Conglei Xu"><meta name="copyright" content="Conglei Xu"><title>week4 | Conglei Xu</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Overview"><span class="toc-number">1.</span> <span class="toc-text">Overview</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#random-package"><span class="toc-number">2.</span> <span class="toc-text">random package</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Tensors-and-Ndarray"><span class="toc-number">2.1.</span> <span class="toc-text">Tensors and Ndarray</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Methods-for-Tensors-Initialization"><span class="toc-number">2.2.</span> <span class="toc-text">Methods for Tensors Initialization</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Indexing-of-Tensors-in-Pytorch"><span class="toc-number">3.</span> <span class="toc-text">Indexing of Tensors in Pytorch</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadnling-Negative-Value-in-Cosine-Similarity"><span class="toc-number">4.</span> <span class="toc-text">Hadnling Negative Value in Cosine Similarity</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Pytorch-Multiprocessing-Combined-with-Early-Stoping"><span class="toc-number">5.</span> <span class="toc-text">Pytorch Multiprocessing Combined with Early Stoping</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Trivial-Knowledge"><span class="toc-number">6.</span> <span class="toc-text">Trivial Knowledge</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://raw.githubusercontent.com/yao2jiang/blog_images/master/bolg_index/new.jpg"></div><div class="author-info__name text-center">Conglei Xu</div><div class="author-info__description text-center"></div><div class="follow-button"><a href="https://github.com/xiaojianhai">Follow me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">19</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">10</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">11</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://raw.githubusercontent.com/yao2jiang/blog_images/master/bolg_index/header.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Conglei Xu</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">week4</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-09-04</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/week-summary/">week summary</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>This week make a conclusion of usage of random backage in Pytorch and Numpy, Cosice similarity and multiprocessing combined with early<br>stoping in Pytorch.</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><h1 id="random-package"><a href="#random-package" class="headerlink" title="random package"></a>random package</h1><h2 id="Tensors-and-Ndarray"><a href="#Tensors-and-Ndarray" class="headerlink" title="Tensors and Ndarray"></a>Tensors and Ndarray</h2><p>The random package can generate Tensors(ndarray) under different distribution, including uniform distribution, stand normal distribution and<br>custom distribution.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">stand normal distribution</span><br><span class="line">torch.randn() </span><br><span class="line">np.random.randn() return either a narray or a float</span><br><span class="line"></span><br><span class="line">uniform distribution random samples from a uniform distribution over [0, 1)</span><br><span class="line">torch.rand()</span><br><span class="line">np.random.rand(shape1, shape0)</span><br><span class="line"></span><br><span class="line">random int numbers over [low, high] with shape s=(9, 9)</span><br><span class="line">torch.randint(low, high, s)</span><br><span class="line">np.random.randint(low, high, s)</span><br><span class="line"></span><br><span class="line">custom operation</span><br><span class="line">np.random.permuation(10) # same as np.random.shuffle(np.arange(10))</span><br><span class="line">t = torch.tensor([[1, 2], [3, 4]])</span><br><span class="line">row = torch.randperm(2)</span><br><span class="line">col = torch.randperm(2)</span><br><span class="line">t = t[row[:, None], col] # row[:, None] add a new dimension for row tensor</span><br><span class="line"></span><br><span class="line">with view</span><br><span class="line">idx = torch.randperm(t.nelement())</span><br><span class="line">t = t.view(-1)[idx].view(t.size)</span><br></pre></td></tr></table></figure>

<h2 id="Methods-for-Tensors-Initialization"><a href="#Methods-for-Tensors-Initialization" class="headerlink" title="Methods for Tensors Initialization"></a>Methods for Tensors Initialization</h2><p>two types of initialization for tensors:<br>by the data.fill_ mehtod of tensor object or by nn.init.method</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">manual initialization</span><br><span class="line">linear_layer = nn.Linear(5, 4)</span><br><span class="line">linear_layer.weight.data.fill_(0.0)</span><br><span class="line">linear_layer.bias.data.fill_(0.0)</span><br><span class="line"></span><br><span class="line">Initialized by nn.init</span><br><span class="line">nn.init.zeros_(weight)  # all initialized methods need a tensor object as the input</span><br><span class="line">nn.init.ones_(weight)</span><br><span class="line">nn.init.uniform(linear_layer.weight, a=0.0, b=1.0)</span><br><span class="line">nn.init.normal_(linear_layer.weight, mean=0.0, std=1.0)</span><br><span class="line"></span><br><span class="line">nn.init.xavier_uniform_(weight)</span><br><span class="line">nn.init.xavier_normal_(weight)</span><br><span class="line"></span><br><span class="line">nn.init.kaiming_uniform(weight, nonlinearity=&apos;relu&apos;)</span><br><span class="line">nn.init.kaiming_normal_(weight, nonlinearity=&apos;relu&apos;)</span><br><span class="line">nn.init.orthogonal_(weight)</span><br><span class="line"></span><br><span class="line">custom initialization</span><br><span class="line">def defiend_initialization(input_tensor):</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">	    tensor.fill_(1.0)</span><br></pre></td></tr></table></figure>

<h1 id="Indexing-of-Tensors-in-Pytorch"><a href="#Indexing-of-Tensors-in-Pytorch" class="headerlink" title="Indexing of Tensors in Pytorch"></a>Indexing of Tensors in Pytorch</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">Integer array indexing</span><br><span class="line">two indicies should have same length and the Indexing is elementwise</span><br><span class="line">row = torch.tensor([1, 2]) #one dimension</span><br><span class="line">columns = torch.tensor([1, 2])</span><br><span class="line"></span><br><span class="line">boolean array Indexing</span><br><span class="line">y = [x&gt;1]</span><br><span class="line"></span><br><span class="line">Mixing integer and slice Indexing</span><br><span class="line">y = x[i, :5]</span><br><span class="line"></span><br><span class="line">None indexing for new slice indexing </span><br><span class="line">y = x[..., None]</span><br><span class="line"></span><br><span class="line">tensor indexing </span><br><span class="line">indicies = torch.tensor([[1, 3], [2, 4]]) # (2 * 2)</span><br><span class="line">t = torch.randn(5, 5)</span><br><span class="line">y = t[indicies]  (2*2*5)</span><br><span class="line"></span><br><span class="line">two tensor indexing by broadcasting </span><br><span class="line">row = torch.tensor([1, 2])</span><br><span class="line">column = torch.tensor([0, 1])</span><br><span class="line">y = t[row[:, None], column]</span><br><span class="line"></span><br><span class="line">row(2) -&gt; row(2, 1), then Indexing broadcasting to row(2, 2) [[1, 1], [2, 2]]</span><br><span class="line">column(2) -&gt; column(2, 2) [[0, 1], [0, 1]]</span><br><span class="line">the result has the shape (len(row), len(column)) each result[i][j] will be t[row[i], [column[j]]</span><br></pre></td></tr></table></figure>

<h1 id="Hadnling-Negative-Value-in-Cosine-Similarity"><a href="#Hadnling-Negative-Value-in-Cosine-Similarity" class="headerlink" title="Hadnling Negative Value in Cosine Similarity"></a>Hadnling Negative Value in Cosine Similarity</h1><p>consine similarity in torch.nn.cosine_similarity() can handle three dimension data</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Rescale_simiarity</span><br><span class="line">Rescale_simiarity = (cosine_similarity + 1) / 2</span><br><span class="line"></span><br><span class="line">Change it to consine distance</span><br><span class="line">cosine_distance = 1 - consine_similarity</span><br></pre></td></tr></table></figure>

<h1 id="Pytorch-Multiprocessing-Combined-with-Early-Stoping"><a href="#Pytorch-Multiprocessing-Combined-with-Early-Stoping" class="headerlink" title="Pytorch Multiprocessing Combined with Early Stoping"></a>Pytorch Multiprocessing Combined with Early Stoping</h1><p>When training neural networks on multi-gpus, it’s essential to use shared variables and a “Lock” to implement early stoping.<br>The primary is to ensure that ass the different processes cease operations at the same point.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Value, Lock  Value are ctype objects, whcih can shared </span><br><span class="line"></span><br><span class="line">def train(*args):</span><br><span class="line">    for epoch in range(1, num_epoch + 1):</span><br><span class="line">	    ...</span><br><span class="line">		with best_f1_lock:</span><br><span class="line">		    if best_f1.value &lt; eval_f1:</span><br><span class="line">			    best_f1.value = eval_f1</span><br><span class="line">				patience_counter = 0</span><br><span class="line">			else:</span><br><span class="line">			    patience_counter += 1</span><br><span class="line">				if patience_counter &gt;= patience:</span><br><span class="line">				    stop.flag.value = 1</span><br><span class="line">		if stop_flag.value == 1:</span><br><span class="line">		    break</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    best_f1 = Value(&apos;d&apos;, -1.0) double float</span><br><span class="line">	best_f1_lock = Lock()</span><br><span class="line">	stop_flag = Value(&apos;i&apos;, 1) flag to signal processes to stop</span><br></pre></td></tr></table></figure>

<h1 id="Trivial-Knowledge"><a href="#Trivial-Knowledge" class="headerlink" title="Trivial Knowledge"></a>Trivial Knowledge</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">torch.sort() return sorted_tensor, and indicies</span><br><span class="line"></span><br><span class="line">for torch.where() the condiion tensor and two tensors &apos;x&apos; and &apos;y&apos; should be broadcastable to the same shape</span><br><span class="line"></span><br><span class="line">torch.where(condition, x, y)</span><br><span class="line"></span><br><span class="line">torch.unsqueeze(x, 0)  add dimension same as x[None, :]</span><br><span class="line">torch.squeeze(x, 0)</span><br><span class="line"></span><br><span class="line">x = torch.ones(5,1)</span><br><span class="line">y = x.repreat(1, 5) (5, 5)</span><br></pre></td></tr></table></figure>

</div></article><div class="post-meta__tag-list"></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2023/09/21/week5/"><i class="fa fa-chevron-left">  </i><span>week5</span></a></div><div class="next-post pull-right"><a href="/2023/08/28/week3/"><span>week3</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://raw.githubusercontent.com/yao2jiang/blog_images/master/bolg_index/header.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2023 By Conglei Xu</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://xiaojianhai.github.io/">blog</a>!</div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body></html>